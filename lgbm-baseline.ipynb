{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_identity.csv', 'sample_submission.csv', 'train_identity.csv', 'train_transaction.csv', 'test_transaction.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime \n",
    "import lightgbm as lgb\n",
    "\n",
    "import os\n",
    "import gc\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 1775.15 MB\n",
      "Memory usage after optimization is: 489.41 MB\n",
      "Decreased by 72.4%\n",
      "Memory usage of dataframe is 1519.24 MB\n",
      "Memory usage after optimization is: 427.17 MB\n",
      "Decreased by 71.9%\n",
      "Memory usage of dataframe is 45.12 MB\n",
      "Memory usage after optimization is: 10.57 MB\n",
      "Decreased by 76.6%\n",
      "Memory usage of dataframe is 44.39 MB\n",
      "Memory usage after optimization is: 10.40 MB\n",
      "Decreased by 76.6%\n"
     ]
    }
   ],
   "source": [
    "train_transaction = reduce_mem_usage(pd.read_csv('../input/train_transaction.csv', index_col='TransactionID'))\n",
    "test_transaction = reduce_mem_usage(pd.read_csv('../input/test_transaction.csv', index_col='TransactionID'))\n",
    "\n",
    "train_identity = reduce_mem_usage(pd.read_csv('../input/train_identity.csv', index_col='TransactionID'))\n",
    "test_identity = reduce_mem_usage(pd.read_csv('../input/test_identity.csv', index_col='TransactionID'))\n",
    "\n",
    "sample_submission = pd.read_csv('../input/sample_submission.csv', index_col='TransactionID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\n",
    "test = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corret_card_id(x): \n",
    "    x=x.replace('.0','')\n",
    "    x=x.replace('-999','nan')\n",
    "    return x\n",
    "\n",
    "def define_indexes(df):\n",
    "    \n",
    "    # create date column\n",
    "    START_DATE = '2017-12-01'\n",
    "    startdate = datetime.datetime.strptime(START_DATE, '%Y-%m-%d')\n",
    "    df['TransactionDT'] = df['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds = x)))\n",
    "    \n",
    "    df['year'] = df['TransactionDT'].dt.year\n",
    "    df['month'] = df['TransactionDT'].dt.month\n",
    "    df['dow'] = df['TransactionDT'].dt.dayofweek\n",
    "    df['hour'] = df['TransactionDT'].dt.hour\n",
    "    df['day'] = df['TransactionDT'].dt.day\n",
    "   \n",
    "    # create card ID \n",
    "    cards_cols= ['card1', 'card2', 'card3', 'card5']\n",
    "    for card in cards_cols: \n",
    "        if '1' in card: \n",
    "            df['card_id']= df[card].map(str)\n",
    "        else : \n",
    "            df['card_id']+= ' '+df[card].map(str)\n",
    "    \n",
    "    # small correction of the Card_ID\n",
    "    df['card_id']=df['card_id'].apply(corret_card_id)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = define_indexes(train)\n",
    "test = define_indexes(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['TransactionAmt_to_mean_card1'] = train['TransactionAmt'] / train.groupby(['card1'])['TransactionAmt'].transform('mean')\n",
    "train['TransactionAmt_to_mean_card4'] = train['TransactionAmt'] / train.groupby(['card4'])['TransactionAmt'].transform('mean')\n",
    "train['TransactionAmt_to_std_card1'] = train['TransactionAmt'] / train.groupby(['card1'])['TransactionAmt'].transform('std')\n",
    "train['TransactionAmt_to_std_card4'] = train['TransactionAmt'] / train.groupby(['card4'])['TransactionAmt'].transform('std')\n",
    "\n",
    "test['TransactionAmt_to_mean_card1'] = test['TransactionAmt'] / test.groupby(['card1'])['TransactionAmt'].transform('mean')\n",
    "test['TransactionAmt_to_mean_card4'] = test['TransactionAmt'] / test.groupby(['card4'])['TransactionAmt'].transform('mean')\n",
    "test['TransactionAmt_to_std_card1'] = test['TransactionAmt'] / test.groupby(['card1'])['TransactionAmt'].transform('std')\n",
    "test['TransactionAmt_to_std_card4'] = test['TransactionAmt'] / test.groupby(['card4'])['TransactionAmt'].transform('std')\n",
    "\n",
    "train['id_02_to_mean_card1'] = train['id_02'] / train.groupby(['card1'])['id_02'].transform('mean')\n",
    "train['id_02_to_mean_card4'] = train['id_02'] / train.groupby(['card4'])['id_02'].transform('mean')\n",
    "train['id_02_to_std_card1'] = train['id_02'] / train.groupby(['card1'])['id_02'].transform('std')\n",
    "train['id_02_to_std_card4'] = train['id_02'] / train.groupby(['card4'])['id_02'].transform('std')\n",
    "\n",
    "test['id_02_to_mean_card1'] = test['id_02'] / test.groupby(['card1'])['id_02'].transform('mean')\n",
    "test['id_02_to_mean_card4'] = test['id_02'] / test.groupby(['card4'])['id_02'].transform('mean')\n",
    "test['id_02_to_std_card1'] = test['id_02'] / test.groupby(['card1'])['id_02'].transform('std')\n",
    "test['id_02_to_std_card4'] = test['id_02'] / test.groupby(['card4'])['id_02'].transform('std')\n",
    "\n",
    "train['D15_to_mean_card1'] = train['D15'] / train.groupby(['card1'])['D15'].transform('mean')\n",
    "train['D15_to_mean_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('mean')\n",
    "train['D15_to_std_card1'] = train['D15'] / train.groupby(['card1'])['D15'].transform('std')\n",
    "train['D15_to_std_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('std')\n",
    "\n",
    "test['D15_to_mean_card1'] = test['D15'] / test.groupby(['card1'])['D15'].transform('mean')\n",
    "test['D15_to_mean_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('mean')\n",
    "test['D15_to_std_card1'] = test['D15'] / test.groupby(['card1'])['D15'].transform('std')\n",
    "test['D15_to_std_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('std')\n",
    "\n",
    "train['D15_to_mean_addr1'] = train['D15'] / train.groupby(['addr1'])['D15'].transform('mean')\n",
    "train['D15_to_mean_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('mean')\n",
    "train['D15_to_std_addr1'] = train['D15'] / train.groupby(['addr1'])['D15'].transform('std')\n",
    "train['D15_to_std_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('std')\n",
    "\n",
    "test['D15_to_mean_addr1'] = test['D15'] / test.groupby(['addr1'])['D15'].transform('mean')\n",
    "test['D15_to_mean_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('mean')\n",
    "test['D15_to_std_addr1'] = test['D15'] / test.groupby(['addr1'])['D15'].transform('std')\n",
    "test['D15_to_std_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_value_cols = [col for col in train.columns if train[col].nunique() <= 1]\n",
    "one_value_cols_test = [col for col in test.columns if test[col].nunique() <= 1]\n",
    "\n",
    "many_null_cols = [col for col in train.columns if train[col].isnull().sum() / train.shape[0] > 0.9]\n",
    "many_null_cols_test = [col for col in test.columns if test[col].isnull().sum() / test.shape[0] > 0.9]\n",
    "\n",
    "big_top_value_cols = [col for col in train.columns if train[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\n",
    "big_top_value_cols_test = [col for col in test.columns if test[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\n",
    "\n",
    "cols_to_drop = list(set(many_null_cols + many_null_cols_test + big_top_value_cols + big_top_value_cols_test + one_value_cols+ one_value_cols_test))\n",
    "\n",
    "cols_to_drop.remove('isFraud')\n",
    "\n",
    "train.drop(cols_to_drop, axis=1, inplace=True)\n",
    "test.drop(cols_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_transaction, train_identity, test_transaction, test_identity\n",
    "\n",
    "target = train['isFraud'].copy()\n",
    "\n",
    "X_train = train.drop('isFraud', axis=1)\n",
    "X_train.drop('TransactionDT', axis=1, inplace=True)\n",
    "X_test = test.drop('TransactionDT', axis=1)\n",
    "\n",
    "del train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in X_train.select_dtypes(include='category').columns.tolist() + X_train.select_dtypes(include='object').columns.tolist():\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(X_train[f].values) + list(X_test[f].values))\n",
    "    X_train[f] = lbl.transform(list(X_train[f].values))\n",
    "    X_test[f] = lbl.transform(list(X_test[f].values))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 491,\n",
    "          'min_child_weight': 0.03454472573214212,\n",
    "          'feature_fraction': 0.3797454081646243,\n",
    "          'bagging_fraction': 0.4181193142567742,\n",
    "          'min_data_in_leaf': 106,\n",
    "          'objective': 'binary',\n",
    "          'max_depth': -1,\n",
    "          'learning_rate': 0.006883242363721497,\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"bagging_seed\": 11,\n",
    "          \"metric\": 'auc',\n",
    "          \"verbosity\": -1,\n",
    "          'reg_alpha': 0.3899927210061127,\n",
    "          'reg_lambda': 0.6485237330340494,\n",
    "          'random_state': 47\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = 5\n",
    "folds = KFold(n_splits = splits)\n",
    "oof = np.zeros(len(X_train))\n",
    "predictions = np.zeros(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.981383\tvalid_1's auc: 0.906923\n",
      "[1000]\ttraining's auc: 0.996552\tvalid_1's auc: 0.917515\n",
      "[1500]\ttraining's auc: 0.999327\tvalid_1's auc: 0.920596\n",
      "[2000]\ttraining's auc: 0.999874\tvalid_1's auc: 0.921223\n",
      "[2500]\ttraining's auc: 0.999984\tvalid_1's auc: 0.921845\n",
      "[3000]\ttraining's auc: 0.999999\tvalid_1's auc: 0.922062\n",
      "[3500]\ttraining's auc: 1\tvalid_1's auc: 0.922051\n",
      "Early stopping, best iteration is:\n",
      "[3117]\ttraining's auc: 0.999999\tvalid_1's auc: 0.922148\n",
      "  auc =  0.9221460086066313\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.981733\tvalid_1's auc: 0.925518\n",
      "[1000]\ttraining's auc: 0.997191\tvalid_1's auc: 0.935895\n",
      "[1500]\ttraining's auc: 0.999579\tvalid_1's auc: 0.937889\n",
      "[2000]\ttraining's auc: 0.999937\tvalid_1's auc: 0.937986\n",
      "[2500]\ttraining's auc: 0.999994\tvalid_1's auc: 0.937789\n",
      "Early stopping, best iteration is:\n",
      "[2122]\ttraining's auc: 0.999963\tvalid_1's auc: 0.938137\n",
      "  auc =  0.938136911531769\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.982923\tvalid_1's auc: 0.922141\n",
      "[1000]\ttraining's auc: 0.997239\tvalid_1's auc: 0.930472\n",
      "[1500]\ttraining's auc: 0.999584\tvalid_1's auc: 0.930867\n",
      "Early stopping, best iteration is:\n",
      "[1324]\ttraining's auc: 0.999207\tvalid_1's auc: 0.931147\n",
      "  auc =  0.9311468967612253\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.981764\tvalid_1's auc: 0.939829\n",
      "[1000]\ttraining's auc: 0.997156\tvalid_1's auc: 0.948536\n",
      "[1500]\ttraining's auc: 0.999588\tvalid_1's auc: 0.949677\n",
      "[2000]\ttraining's auc: 0.999946\tvalid_1's auc: 0.949393\n",
      "Early stopping, best iteration is:\n",
      "[1726]\ttraining's auc: 0.999834\tvalid_1's auc: 0.949731\n",
      "  auc =  0.9497311765130974\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.982094\tvalid_1's auc: 0.916609\n",
      "[1000]\ttraining's auc: 0.99703\tvalid_1's auc: 0.925453\n",
      "[1500]\ttraining's auc: 0.999531\tvalid_1's auc: 0.926152\n",
      "[2000]\ttraining's auc: 0.99993\tvalid_1's auc: 0.92573\n",
      "Early stopping, best iteration is:\n",
      "[1507]\ttraining's auc: 0.99954\tvalid_1's auc: 0.92619\n",
      "  auc =  0.9261895494231125\n"
     ]
    }
   ],
   "source": [
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train.values, target.values)):\n",
    "    print(\"Fold {}\".format(fold_))\n",
    "    train_df, y_train_df = X_train.iloc[trn_idx], target.iloc[trn_idx]\n",
    "    valid_df, y_valid_df = X_train.iloc[val_idx], target.iloc[val_idx]\n",
    "    \n",
    "    trn_data = lgb.Dataset(train_df, label=y_train_df)\n",
    "    val_data = lgb.Dataset(valid_df, label=y_valid_df)\n",
    "    \n",
    "    clf = lgb.train(params,\n",
    "                    trn_data,\n",
    "                    10000,\n",
    "                    valid_sets = [trn_data, val_data],\n",
    "                    verbose_eval=500,\n",
    "                    early_stopping_rounds=500)\n",
    "\n",
    "    pred = clf.predict(valid_df)\n",
    "    oof[val_idx] = pred\n",
    "    print( \"  auc = \", roc_auc_score(y_valid_df, pred) )\n",
    "    predictions += clf.predict(X_test) / splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = sample_submission.reset_index()\n",
    "sample_submission[\"isFraud\"] = predictions\n",
    "sample_submission.to_csv(\"lgb_sub.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
